{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robotics Foundations (H) - Lab 4\n",
    "\n",
    "## ILOs\n",
    "\n",
    "At the end of the lab, you should be able to:\n",
    "* Deepen your understanding about ROSâ€™ motion planning framework MoveIt\n",
    "* Use MoveIt Python API to program a data processing pipeline for locating an object, grasping it and placing it in another location."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robotic Pick-'n-Place\n",
    "\n",
    "Robotic pick and place tasks are central to any production line. The reason is that companies want to increase production rates of their manufactured products. Pick and place robots can be customised to fit specific production requirements by moving large, small, bulky, or hard-to-handle products in the factory lines. Hence, this lab aims to build a ROS package that allows Baxter to pick and place objects in the simulation.\n",
    "\n",
    "For the above, we have already developed a ready-to-use ROS package that uses MoveIt! to command Baxter to pick up and object and place it somewhere else. This ROS package is available in the lab's folder at (press Ctrl-Enter next cell):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd ~/Desktop/RFLabs/lab4/src\n",
    "ls -R --color=yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a quick demo, copy `lab4_pkg` to your `rf_ws` (i.e. `cp -r ~/Desktop/RFLabs/lab4/src/* ~/rf_ws/src`), `catkin_make` rf_ws workspace and source your workspace. Thereafter, run the following in separate terminals:\n",
    "    \n",
    "Terminal 1:\n",
    "``` bash\n",
    "roslaunch baxter_gazebo baxter_world.launch\n",
    "```\n",
    "\n",
    "Terminal 2:\n",
    "``` bash\n",
    "rosrun baxter_tools enable_robot.py -e\n",
    "rosrun baxter_interface joint_trajectory_action_server.py\n",
    "```\n",
    "\n",
    "Terminal 3:\n",
    "``` bash\n",
    "roslaunch baxter_moveit_config baxter_grippers.launch\n",
    "```\n",
    "\n",
    "Terminal 4:\n",
    "``` bash\n",
    "rosrun lab4_pkg pick_and_place_moveit.py\n",
    "```\n",
    "**NOTE: You may need to make `pick_and_place_moveit.py` executable with `chmod +x`**\n",
    "\n",
    "Open the `pick_and_place_moveit.py` and inspect the code to know what's going on! (we'll explain later in the notebook the different components) *Was Baxter successful at picking up the object all the time?* If yes, you might have been lucky, but the script is not 100% reliable; picking or placing fails at some point... even in simulation! (Figure 1)\n",
    "\n",
    "![pnp_fail.png](imgs/pnp_fail.png)\n",
    "<div style=\"text-align:center\"><b>Figure 1: Pick and place failure</b><br></div>\n",
    "\n",
    "The reason is that Baxter does not have any feedback (vision, tactile, etc.), among other uncertainties such as Baxter's compliance and mechanical inaccuracies. Robots in production lines rely on a fixed and **very** controlled environment for pick and place tasks. Some might have computer vision or another type of sensing modality to locate objects. However, dexterous pick and place tasks are still an open research problem. A quick hack for this example is to modify`pick_and_place_moveit.py` to update the object's location every time Baxter places it (using TF as you will cover in this lab) or, even add vision capabilities to Baxter (as you will do in Lab 5)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gazebo models\n",
    "\n",
    "The above script implements two useful functions: `load_gazebo_models` and `delete_gazebo_models`. Both functions allow you to add objects in the simulation during runtime from a URDF, SDF and CAD files. `load_gazebo_models` reads both the box and table models and then spawns them into the simulator. `delete_gazebo_models` clears the objects from the simulator. This is useful when you want to change the scene.\n",
    "\n",
    "If you inspect the `pick_and_place_moveit.py` code, you will notice that the table object is an SDF file ([Simulation Description Format](http://sdformat.org/)). SDF files are similar to URDF files, in the sense that they define geometries for Gazebo. You can read SDF files as standard URDF/XML files. You can find the full specification here: http://sdformat.org/spec. For RF, you do not need to build SDF files. There is a wide range of objects in [Gazebo's library](http://models.gazebosim.org/) that you can use; for now, stick with the table and the red block."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding simulated objects in RViz\n",
    "\n",
    "MoveIt! needs to know about the robot's environment to avoid hitting objects and damage the robot (especially when using the real robot) such as the coffee table. Right now, the objects you have in the simulation don't appear in RViz, Figure 2. So, you have two possible options:\n",
    "\n",
    "![combined.png](imgs/combined.png)\n",
    "<div style=\"text-align:center\"><b>Figure 2: RViz without simulated objects</b><br></div>\n",
    "\n",
    "1. Add a vision sensor, recognise the scene and add the objects in RViz using MoveIt! Planning Scene API, or\n",
    "2. Transfer the simulated objects from Gazebo into Rviz\n",
    "\n",
    "The former is, in fact, the topic of the following labs. The latter can be solved with a ROS package that someone else has developed before. ROS developers predicate that *If someone has a way to solve your problem, then find it since there's no need to reinvent the wheel!* In reality, this doesn't hold true all the time because\n",
    "\n",
    "* packages are not updated,\n",
    "* they don't follow good software engineering principles,\n",
    "* they are \"spaghetti code\" which makes difficult the task of tracking down dependencies; or\n",
    "* they are not documented at all.\n",
    "\n",
    "Luckily, the ROS package ([`pysdf`](http://wiki.ros.org/pysdf)) does what you want for option 2 above (almost) out of the box. `pysdf` is already installed in the virtual machine, so you do not need to worry about this. To use `pysdf`, you need to run the following in a terminal (each command at a time):\n",
    "\n",
    "``` bash\n",
    "roscd baxter_sim_examples/models/cafe_table\n",
    "export MESH_WORKSPACE_PATH=~/ros_ws/src\n",
    "rosrun pysdf sdf2urdf.py model.sdf model.urdf\n",
    "```\n",
    "\n",
    "The above will create a URDF file from an SDF file. To integrate the URDF file in Baxter's descriptions (i.e. Baxter's xacro files, see lab2 for a refresher), you need to change `model.urdf` to a XACRO file; otherwise XACRO will fail while parsing Baxter's files. So, copy `model.urdf` to your `lab4_pkg` with `cp model.urdf ~/rf_ws/src/lab4_pkg/src/cafe_table.xacro` (note that we are already changing the file extension to `xacro`), go to `~/rf_ws/src/lab4_pkg/src/` and open `cafe_table.xacro` using your prefered editor, and do the following to make `cafe_table.xacro` Xacro compatible:\n",
    "\n",
    "1. Replace `<robot name=\"cafe_table\">` with `<robot name=\"cafe_table\" xmlns:xacro=\"http://www.ros.org/wiki/xacro\">`\n",
    "2. Add a joint of the coffee table (aka `cafe_table`) such that Rviz and TF can understand where the coffee table is located in space and its place within the robot's and environment's transformation hierarchy. In here, we attach the table to the world, so copy/paste the code below just before the `robot` closing tag in `cafe_table.xacro`. Save the file after you finish adding the code below.\n",
    "\n",
    "``` xml\n",
    "<joint name=\"cafe_table_fixed\" type=\"fixed\">\n",
    "  <origin rpy=\"0 0 0\" xyz=\"1.0 0 -0.93\"/>\n",
    "  <axis xyz=\"0 0 1\"/>\n",
    "  <parent link=\"world\"/>\n",
    "  <child link=\"cafe_table__link\"/>\n",
    "</joint>\n",
    "```\n",
    "\n",
    "3. Open `baxter.urdf.xacro` which is located at `~/ros_ws/src/baxter/baxter/baxter_common/baxter_description/urdf/` (this is the main XACRO file that puts together Baxter's transformations, links and joints) and add the following just before the `robot` closing tag:\n",
    "\n",
    "``` xml\n",
    "<!-- Coffe Table -->\n",
    "<xacro:include filename=\"$(find lab4_pkg)/src/cafe_table.xacro\" />\n",
    "```\n",
    "\n",
    "4. Save all your files and you are now ready to test your new robot description. For this, you need to Ctrl-C all terminals because we have updated Baxter's XACRO file, and changes to any xacro file are not picked up on runtime. Then run the following (remember to source your `rf_ws` on every terminal you open because your new table XACRO file is in the rf workspace!):\n",
    "\n",
    "``` bash\n",
    "roslaunch baxter_gazebo baxter_world.launch\n",
    "rosrun baxter_tools enable_robot.py -e\n",
    "rosrun baxter_interface joint_trajectory_action_server.py\n",
    "```\n",
    "\n",
    "and, finally, launch RVIZ with MoveIt:\n",
    "\n",
    "``` bash\n",
    "roslaunch baxter_moveit_config baxter_grippers.launch\n",
    "```\n",
    "\n",
    "Plan different trajectories (as in lab3) and see what happens! Baxter should avoid the table! Gazebo will not have the table in the simulation until you run `pick_and_place_moveit.py` which loads the coffee table SDF file -- don't do it now, we'll get to run the node later. This is because we have only specified the model for RViz to make the robot \"aware\" that there's a table in front of it. RViz is the visualisation of what the robot is \"thinking\", and it will not reflect what happens in reality until you add an object to Gazebo.\n",
    "\n",
    "Try moving Baxter's arms towards the table, and you will be able to see that the links that are in collision will turn in red, and you will not be able to plan and execute a trajectory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Gazebo to TF frames\n",
    "\n",
    "The table is fixed, but the red block will change its position and orientation when Baxter interacts with it. Gazebo will handle the interaction for you, but the robot and, consequently, RViz will not have an idea where the block is with respect to the robot. So let's address the issue of no feedback by retrieving the position and orientation (pose) of the red block. For this, we need to query the state of the simulation, and we can write a ROS node to accomplish this! \n",
    "\n",
    "This node will be based on the [\"Writing a TF broadcaster (Python)\"](http://wiki.ros.org/tf/Tutorials/Writing%20a%20tf%20broadcaster%20%28Python%29) from ROS official tutorials -- It is always a good idea to check ROS tutorials! Copy and paste the following code into a Python file, and save it in your 'lab4_pkg/src' folder as `gazebo2tfframe.py` (you can create a new file using the File Manager). Do go over the code below, so you get an idea of what we are trying to accomplish.\n",
    "\n",
    "``` python\n",
    "#!/usr/bin/env python\n",
    "import rospy\n",
    "import tf\n",
    "from gazebo_msgs.msg import LinkStates\n",
    "\n",
    "# This is hard-coded to block for this exercise, yet you can make the script general by adding cmd line arguments\n",
    "input_linkname = \"block\"\n",
    "\n",
    "# Global variable where the object's pose is stored\n",
    "pose = None\n",
    "\n",
    "\n",
    "def get_links_gazebo(link_states_msg):\n",
    "    # Call back to retrieve the object you are interested in\n",
    "    global input_linkname\n",
    "    global pose\n",
    "    poses = {'world': link_states_msg.pose[0]} # get world link\n",
    "    for (link_idx, link_name) in enumerate(link_states_msg.name):\n",
    "        modelname = link_name.split('::')[0]\n",
    "        if input_linkname == modelname:\n",
    "            poses[modelname] = link_states_msg.pose[link_idx]\n",
    "\n",
    "    pose = poses[input_linkname]\n",
    "\n",
    "\n",
    "def main():\n",
    "    rospy.init_node('gazebo2tfframe')\n",
    "\n",
    "    # Create TF broadcaster -- this will publish a frame give a pose\n",
    "    tfBroadcaster = tf.TransformBroadcaster()\n",
    "    # SUbscribe to Gazebo's topic where all links and objects poses within the simulation are published\n",
    "    rospy.Subscriber('gazebo/link_states', LinkStates, get_links_gazebo)\n",
    "\n",
    "    rospy.loginfo('Spinning')\n",
    "    global pose\n",
    "    rate = rospy.Rate(20)\n",
    "    while not rospy.is_shutdown():\n",
    "        if pose is not None:\n",
    "            pos = pose.position\n",
    "            ori = pose.orientation\n",
    "            rospy.loginfo(pos)\n",
    "            # Publish transformation given in pose\n",
    "            tfBroadcaster.sendTransform((pos.x, pos.y, pos.z - 0.93), (ori.x, ori.y, ori.z, ori.w), rospy.Time.now(), input_linkname, 'world')\n",
    "            rate.sleep()\n",
    "\n",
    "    rospy.spin()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "```\n",
    "\n",
    "To test the above script, run the following in different terminals. We assume that you have Gazebo and RViz up and running. If not, go back to step 4 in the previous section and rerun Gazebo and RViz. You should also make the above Python script executable!\n",
    "\n",
    "``` bash\n",
    "rosrun lab4_pkg pick_and_place_moveit.py\n",
    "rosrun lab4_pkg gazebo2tfframe.py\n",
    "```\n",
    "\n",
    "`gazebo2tfframe.py` will print in the terminal the block's position. In RViz, make sure you have the `RobotModel` and `TF` plugins enabled. Figure 3 shows an example of what you should get. If you get the names of each link, you can turn them off by navigating to `TF` in `Displays`, and uncheck `Show Names`; alternatively, you can disable showing all frames by navigating to `TF -> Frames` and uncheck `All Enabled`, then only check `block`. You may notice that the block will start moving for no reason, this is a bug in Gazebo which we have reported a while ago and it appears it will never be fixed...\n",
    "\n",
    "![new_frame.png](imgs/new_frame.png)\n",
    "<div style=\"text-align:center\"><b>Figure 3: New frame from an object within Gazebo's simulation</b><br></div>\n",
    "\n",
    "### Challenge!\n",
    "\n",
    "It is now possible to make the pick and place Python script more robust. We recommend you give it a try and ask us if you get stuck! Detecting where is the block will be a core functionality for your assessed coursework. **Tip: You need to listen to the TF transformation from base to block (see Lab 2) in order to query the block's pose. You should do the latter in the pick and place Python script.** You can verify if your solution is valid if Baxter can go towards the block and pick it up successfully!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
